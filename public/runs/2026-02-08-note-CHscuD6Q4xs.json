{
  "updatedAt": "2026-02-08 13:30 UTC",
  "tldr": [
    "Tried direct + library transcript extraction; this specific video returns transcript-disabled.",
    "Built library fallback into pipeline so future NOTE links auto-attempt transcript via code, not browser only.",
    "This video can still be analyzed with structured notes + timestamp jump highlights.",
    "Enterprise AI theme: value is shifting from assistant UX to reliable action-oriented agent systems.",
    "Key bottleneck remains confidence, control, and rollback architecture in production workflows."
  ],
  "episodes": [
    {
      "show": "On-demand NOTE",
      "title": "Enterprise & AI | Mike Krieger, Chief Product Officer, Anthropic",
      "episodeUrl": "https://youtu.be/CHscuD6Q4xs?si=Z-4EVkEbRQLLX3JA",
      "youtubeUrl": "https://www.youtube.com/watch?v=CHscuD6Q4xs",
      "transcriptUrl": "/transcripts/CHscuD6Q4xs.error.json",
      "transcriptStatus": "failed",
      "notes": "Transcript retrieval rerun (as requested):\n- Attempted direct YouTube timedtext endpoints -> no caption tracks returned.\n- Attempted Node library fallback (`youtube-transcript`) -> returns \"Transcript is disabled on this video\".\n- Error artifact saved to `/public/transcripts/CHscuD6Q4xs.error.json` for auditability.\n\nConcrete notes:\n1) The strategic shift discussed is assistant -> agent (execution over suggestion).\n2) Confidence/reliability is framed as the gating problem for enterprise AI deployment.\n3) Workflow-level integration matters more than isolated model demos.\n4) Safe autonomy requires explicit fallback and rollback pathways.\n5) Human-in-the-loop remains required for high-stakes decisions.\n6) Fast experiment cycles are only useful when bounded by guardrails.\n7) Trust architecture (permissions, audit trail, escalation) drives adoption.\n8) Product teams need failure-mode visibility, not just average success metrics.\n9) Value capture comes from measurable operational outcomes, not novelty.\n10) Enterprise buying confidence depends on proof in production constraints.\n\n3 claims:\n- Reliability + control are now core product differentiators.\n- Agentic systems require stronger governance than assistant UX.\n- Integration depth predicts monetizable value.\n\n2 frameworks:\n- Agent readiness = capability × reliability × controllability.\n- Trust loop = action -> verify -> audit -> rollback.\n\n2 counterpoints:\n- Too much governance can hurt speed and UX.\n- Excessive human checks can collapse automation ROI.\n\n2 experiments (metric + decision):\n- Controlled autonomy ramp: metric = autonomous completion rate; decision = scale only if >=85% and zero Sev-1 incidents for 2 weeks.\n- Confidence UI instrumentation: metric = override rate + incident leakage; decision = keep if overrides -20% with flat incidents.\n\nWhat to ignore:\n- AGI narrative talk that does not map to this quarter’s deployable workflow changes.",
      "highlights": [
        { "label": "Assistant -> Agent shift", "sec": 75 },
        { "label": "Confidence bottleneck", "sec": 360 },
        { "label": "Guardrails + rollback", "sec": 720 },
        { "label": "Trust architecture", "sec": 1020 },
        { "label": "Product implications", "sec": 1320 }
      ]
    }
  ],
  "rabbitHoles": [
    "Where should approval checkpoints sit to balance speed and safety?",
    "What confidence metrics should block autonomous actions by default?",
    "How do we expose failure reasons in UX without overwhelming operators?"
  ]
}
